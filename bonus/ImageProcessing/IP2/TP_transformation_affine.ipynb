{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "    <td width=10%>\n",
    "        <img src=\"images/eisti_logo.png\">\n",
    "    </td>\n",
    "    <td>\n",
    "        <center>\n",
    "            <h1>Deep Learning et Applications</h1>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=15%>\n",
    "        Yann Vernaz  et Paul Gay\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<br/>\n",
    "<div id=\"top\"></div>\n",
    "<center>\n",
    "    <a style=\"font-size: 20pt; font-weight: bold\">Géometrie, caméra et Structure from Motion </a>\n",
    "</center>\n",
    "<br/>\n",
    "\n",
    "##  Retrouvez les paramètres d'une transformation Affine\n",
    "\n",
    "Dans cette première partie, nous verrons les différentes étapes permettant d'estimer une transformation entre deux images. \n",
    "* Détection de points de correspondances\n",
    "* Construction du système d'équations\n",
    "* Résolution par la méthode des moindres carrés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some usefull imports\n",
    "import matplotlib.pyplot as plt, matplotlib\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir l'image distordue\n",
    "\n",
    "Complétez le code ci-dessous afin d'appliquer la transformation affine définie par les matrices A et B à l'image du babouin. Vous pouvez utiliser le même code que pour le cours précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infilename = \"/home/paul/Documents/cours/eisti/slides/TI_01_image_convolutions/tmp/babouin.jpeg\"\n",
    "img = cv2.imread(infilename)\n",
    "img = np.fliplr(img.reshape(-1,3)).reshape(img.shape)\n",
    "distorted_image = np.zeros(img.shape)\n",
    "A = np.array(((0.9, 0.1),(0.2,1)))\n",
    "B = np.array((20, 20))\n",
    "# votre code ici \n",
    "\n",
    "distorted_image = distorted_image.astype(np.uint8)\n",
    "plt.imshow(distorted_image)\n",
    "plt.axis('off')\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calcul des correspondances\n",
    "\n",
    "Le code ci-dessous utilise les fonctions de matching de la librairie Opencv afin de trouver des points de correspondance entre l'image originale et l'image distordue. Il existe différents types de points d'intérêt dans la littérature. Nous utilisons ici les points ORB qui sont réputés pour la rapidité avec laquelle on les calcule et sont très utilisés en reconstruction 3D. \n",
    "\n",
    "Prenez le temps de faire varier les transformations A et B afin d'appliquer et de calculer les correspondances pour différentes paires d'images. Vous vous apercevrez que si l'image est très déformée, certaines correspondances, ne correspondrant pas aux mêmes parties du singe.\n",
    "\n",
    "Que se passera t'il alors si nous calculons la transformation en prenant en compte ces points?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "# find the keypoints and descriptors with ORB\n",
    "# ... for the original image\n",
    "kp1, des1 = orb.detectAndCompute(img,None)\n",
    "# ... and for the transformed image\n",
    "kp2, des2 = orb.detectAndCompute(distorted_image,None)\n",
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "# Draw the first matches ie the ones for which the descriptors are similar.\n",
    "number_of_matches = 20\n",
    "img3 = cv2.drawMatches(img,kp1,distorted_image,kp2,matches[:number_of_matches],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.imshow(img3)\n",
    "plt.savefig(\"mismatch.png\",  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelques mots sur les objets fournis par opencv. \n",
    "\n",
    "Le calcul de correspondances se basent en fait sur deux algorithmes : \n",
    " * Un premier algorithme afin de détecter des candidats potentiels de points intéressants, qui seront facilement retrouvables dans l'image déformée. Typiquement, cela correspond aux zones contenant de la texture, et ne correspond pas aux zones de l'image uniformes.\n",
    " * Un deuxième algorithme servant à calculer un descripteur pour chaque point retenu. C'est ce descripteur qui est utilisé par la fonction `bf.match`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correspondance = 0\n",
    "print('Pour la correspondance : ', num_correspondance)\n",
    "print(\"le point\", matches[0].queryIdx, \" de coordonnées\",kp1[matches[0].queryIdx].pt, \"de l'image originale\")\n",
    "print(\"... a une correspondance ... \" )\n",
    "print(\"avec le point\", matches[0].trainIdx, \"de coordonnées\", kp2[matches[0].trainIdx].pt, \"détecté sur l'image distordue\")\n",
    "print()\n",
    "print(\"Nous pouvons vérifier qu'appliquer la transformation sur le premier point permet de retrouver un point proche du point détecté:\")\n",
    "projection = A.dot(np.array((kp1[matches[0].queryIdx].pt[1],kp1[matches[0].queryIdx].pt[0]))) + B\n",
    "print('point détecté : ',kp2[matches[0].trainIdx].pt)\n",
    "print('point projeté :', (projection[1], projection[0]))\n",
    "print(\"C'est donc que cette paire sera utile pour estimer la transformation!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction et résolution du système d'équations\n",
    "\n",
    "Nous cherchons à présent les nouvelles matrices `Ap` et `Bp` telles que le point sur l'image orginale\n",
    "```\n",
    "kp1[matches[0].trainIdx]\n",
    "```\n",
    "soient proche de : \n",
    "```\n",
    "Ap.dot(np.array((kp2[matches[0].queryIdx].pt[1],kp1[matches[0].queryIdx].pt[0]))) + Bp\n",
    "```\n",
    "\n",
    "Vous devez pour celà former le système d'équations, c'est à dire la matrice des observations U et p.\n",
    "\n",
    "Afin que cela fonctionne, assurez vous que les correspondances que vous utilisez sont correctes et n'utilisez que les celles dont la distance est faible, par exemple, les 10 premières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_match = 10 # number of matches used to compute\n",
    "# votre code ici \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez maintenant la méthode de la pseudo inverse pour trouver les matrices Ap et Bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification de la qualité de notre estimation\n",
    "\n",
    "Utilisez la transformation que vous venez de calculer pour corriger l'image distordue et lui rendre sa forme originale. Vous pouvez ré-utiliser la cellule qui transforme l'image en changeant les matrices `A` et `B` par vos nouvelles matrices `Ap` et `Bp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_projected = np.zeros(distorted_image.shape)\n",
    "\n",
    "# votre code ici\n",
    "\n",
    "back_projected = back_projected.astype(np.uint8)\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 20]\n",
    "fig=plt.figure()\n",
    "fig.add_subplot(1,3,1)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(1,3,2)\n",
    "imgplot = plt.imshow(distorted_image)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(1,3,3)\n",
    "imgplot = plt.imshow(back_projected)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faites variez le nombre de points d'intérêts utiliser lors de la transformation (variables `number_of_matches`). \n",
    "\n",
    "Observez que de mauvaises correspondances vont aboutir à une mauvaise transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
