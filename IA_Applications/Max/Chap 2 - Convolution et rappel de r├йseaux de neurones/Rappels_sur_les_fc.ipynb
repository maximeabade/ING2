{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6312cc5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h1 style=\"border: 2px solid black; padding: 15px; border-radius: 12px;\" align='center'>Cours IA et Applications</h1>    \n",
    "\n",
    "<h2 align='center'> Deep Learning : Rappels sur les réseaux Fully Connected </h2>\n",
    "\n",
    "<h3 align='center'> Jordy Palafox </h3>\n",
    "<h3 align='center'> Ing2 GSI/MI - 2023/2024 </h3>\n",
    "      \n",
    "      \n",
    "<div style=\"display:flex\"> \n",
    "    <img src=\"cytech.png\", style=\"width:250px;height:50\"> \n",
    "    <img src=\"cy.jpg\", style=\"width:300px;height:100px\"> \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdd512",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un point sur matériel et logiciel :\n",
    "\n",
    "+ Vous disposez des ordinateurs de l'école avec un Processeur Intel mais **sans GPU**,\n",
    "\n",
    "+ Avec quoi coder en Python pour du Deep Learning :\n",
    "    - En **Script** : *fichier.py *puis on compile *python fichier.py* (le plus fréquent dans la vraie vie pour la mise en production,\n",
    "    - En **Notebook Jupyter**: *notebook.ipynb* pour réaliser des tests,\n",
    "    - Avec **Google colab** => pas de problème de ressources si on utilise pas les GPU/TPU (pour des tests sans problème de version)\n",
    "    \n",
    "+ En local, on peut utiliser les distributions/logiciels **Jupyter**, **VSCode** ou encore **Anaconda**.\n",
    "\n",
    "Dans le cours, vous utiliserez **Google Colab** pour la simplicité :\n",
    "+ Pas de problème de mémoire avec les environnements\n",
    "+ Pas de problème de compatibilité de version !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86863f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quelques rappels sur Tensorflow, Keras et le calcul sur GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0705b7",
   "metadata": {},
   "source": [
    "Importer les différentes libraires : \n",
    "   - *tensorflow* pour faire du deep learning https://www.tensorflow.org/?hl=fr\n",
    "   - *keras* qui se situe dans tensorflow https://keras.io/ créée par François Chollet (ingénieur chez Google), particulièrement accessible et documentée\n",
    "   - *numpy* pour le calcul matriciel\n",
    "   - *pandas* pour manipuler des dataframes\n",
    "   - *pyplot* de matplotlib pour faire de la visualisation\n",
    "   \n",
    "**Remarque** : il y a souvent beaucoup de messages quand on charge tensorflow (des warnings, qui ne sont pas forcément des erreurs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1bd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ... as ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047c890",
   "metadata": {},
   "source": [
    "On pensera à vérifier la version de tensorflow et keras *xxxx.\\_\\_version\\_\\_*\n",
    "\n",
    "Cela peut permettre de vérifier si les versions sont compatibles par ailleurs.\n",
    "\n",
    "Aussi, vérifier si une GPU est indisponible ou non pour faire les calculs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807aa3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow GPU version :\", .........)\n",
    "print('Keras version :', .........)\n",
    "\n",
    "\n",
    "print('GPUs available :', len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815886c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Testons sur une GPU est accessible \n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        #Currenlty memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus :\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical devices\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b6798",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Les **cartes graphiques** (ou **GPU** : Graphics Processing Unit) ont permis l'essor du Deep Learning avec une grande accessibilité à \"madame/monsieur Tout le monde\" \n",
    "        ![image](evolution_nombre_parametre.png)\n",
    "        Source : [Fournarakis] \"*A Practical Guide to Neural Network Quantization*\" voir : https://cms.tinyml.org/wp-content/uploads/industry-news/tinyML_Talks-_Marios_Fournarakis_210929.pdf\n",
    "        \n",
    "En effet, les GPU/TPU permettent **d'accèlerer grandement la vitesse de calculs en les parallélisant** (voir Deep Learning option IA en Ing3 :) ).\n",
    "\n",
    "Avec celles-ci il y a d'autres problèmes posés (métaux rares, consommation énergétique etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778138a",
   "metadata": {},
   "source": [
    "# Chargement et exploration du dataset MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8510c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On va voir maintenant comment implémenter un Réseau de Neuronnes FC en Python \n",
    "sur un jeu de données classique : *MNIST*, qui sont des images de chiffres écrits à la main.\n",
    "https://keras.io/api/datasets/mnist/\n",
    "\n",
    "*Remarque* : on peut directement charger sous la forme d'un dataset d'entrainement et un de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b9e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le jeu de données mnist en une partie d'entraînement et une partie de test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbdc3bb",
   "metadata": {},
   "source": [
    "Voyons la répartition train/test et les formes des images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')\n",
    "print(f'Il y a { ...... } images d\\'entrainement et { ...... } de test.')\n",
    "print('--'*20)\n",
    "print('Les images sont au format {} donc {} pixels par {} pixels.'.format(...... ,\n",
    "   ...... , ...... ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecadc01b",
   "metadata": {},
   "source": [
    "Regardons le type de l'image 5485 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bac786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d93a7d9",
   "metadata": {},
   "source": [
    "C'est un type de numpy, c'est le type le commun pour tensorflow et keras, d'autres librairies de deep learning nécessite des types particuliers comme Pytorch (en soit ça ne change pas grand chose et on peut les conversions entre les différents types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977d6d2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Jetons un coup d'oeil aux données avec la première image et son étiquette (label) associée :\n",
    "\n",
    "x_train[0][0:5]\n",
    "# Il n'y a que des valeurs 0 donc essayons plus loin : \n",
    "\n",
    "x_train[0][10:15]\n",
    "# voilà, les valeurs correspondent au niveau de gris : les valeurs dans les images sont entre 0 et 255 !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fe667",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Remarque sur les tenseurs\n",
    "\n",
    "Une image peut être vue comme un **tenseur** qui est une généralisation de la notion de matrice en dimensions supérieures.\n",
    "En dimension 2, un tenseur est donc une matrice (que l'on peut imaginer comme un rectangle).\n",
    "En dimension 3, un tenseur est une matrice avec une \"profondeur\".\n",
    "\n",
    "Une image en niveau de gris va donc être un tenseur en dimension 3 : *largeur x hauteur x 1* où la dernière dimension correspond au *<span style=\"color:grey\">niveau de gris</span>* c'est donc comme on l'a vu une simple matrice telle que :\n",
    "$$ coef \\in [0,255] $$ \n",
    "\n",
    "Alors qu'une image en couleur (RGB) sera un tenseur en dimension 5 :\n",
    "*largeur x hauteur x 3*\n",
    "avec :\n",
    "+ un canal pour le <span style=\"color:red\">niveau de rouge</span>, \n",
    "+ un canal pour le <span style=\"color:green\">niveau de vert</span>,\n",
    "+ un canal pour le <span style=\"color:blue\">niveau de bleu</span>).  \n",
    "\n",
    "![image](rgb.png)\n",
    "\n",
    "C'est donc un objet représenté par trois matrices supposées ou encore chaque pixel est un vecteur de longueur 3 représentant les différents niveaux de couleurs.\n",
    "\n",
    "\n",
    "Affichons maintenant quelques images du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d06ff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "images_to_display = x_train[np.random.choice(x_train.shape[0],10)]\n",
    "\n",
    "print('Exemples d\\'images du dataset Mnist'.center(50))\n",
    "print('========================'.center(50))\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, x_train, y_train):\n",
    "    i=0\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.text(i+1,3,'--'*5)\n",
    "    ax.text(i+5, 0,f'Label : {label}')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8814ad",
   "metadata": {},
   "source": [
    "# Prétraitement des images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307c9ac",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FCF550; border-radius: 10px; border: 5px solid  orange; padding: 5px;height: 100px; margin: auto;\">\n",
    "    On va réaliser maintenant du <strong>préprocessing</strong>.\n",
    "\n",
    "Sur des images, un classique est de diviser par la valeur max pour **mettre à l'échelle**.\n",
    "Ainsi toutes les valeurs sont entre **0 et 1**.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ec5c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train / ... .\n",
    "x_test = x_test /... .\n",
    "\n",
    "x_train[0][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557811ac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "De plus, les réseaux FC ne prennent pas en entrée que des tenseurs de dimension 1, c'est-à-dire des **vecteurs**.\n",
    "\n",
    "Pour cela, on va transformer l'image sous forme de matrice de taille (28,28) par un \n",
    "vecteur de longueur 28x28 à l'aide de la fonction reshape :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ...\n",
    "x_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fec81",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il faut maintenant pré-traiter les labels car on traite un problème de **classification**\n",
    "et non de **régression** hors les vecteurs y_train et y_test sont remplies de valeurs numériques\n",
    "et non de modalités.\n",
    "\n",
    "On a donc : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c9b62",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7e4a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Chaque label devient un vecteur avec un 1 à la position correspondante au chiffre/label, c'est ni plus ni moins que du one-hot encoding !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450f91a",
   "metadata": {},
   "source": [
    "# Création d'un modèle simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83c781",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On va maintenant définir un modèle simple sous trois formes différentes :\n",
    "\n",
    "Commencons par le mode Sequentiel.\n",
    "\n",
    "Il suffit de définir un objet (le modèle) comme Sequentiel et d'ajouter les couches avec les paramètres voulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de keras importer layers et Sequential\n",
    "\n",
    "...\n",
    "\n",
    "# Créer un modèle avec Sequential :\n",
    "# le première couche doit avoir 32 unités et l'activation de votre choix, n'oubliez pas de préciser la taille de l'entrée,\n",
    "# une deuxième couche cachée avec 64 unités ou neurones,\n",
    "# la couche de sortie doit avoir 10 sorties (une par classe), bien choisir la fonction d'activation\n",
    "\n",
    "model = Sequential()\n",
    "...\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97656e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec summary vérifier l'architecture du modèle \n",
    "\n",
    "model. ...\n",
    "\n",
    "# Quel est le nombre de paramètres ? \n",
    "\n",
    "# Retrouvez-ce nombre à la main !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52038d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La modèle a 27882 paramètres, tous \"entraînables\", i.e pourront être mis à jour par l'optimiseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f9e1b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model1_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae638d2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FCF550; border-radius: 10px; border: 5px solid  orange; padding: 5px;height: auto; margin: auto;\">\n",
    "    En résumé ... </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b0631",
   "metadata": {},
   "source": [
    "![image](network1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce0940",
   "metadata": {},
   "source": [
    "# Compilation du modèle\n",
    "Permet la configuration du modèle, c'est-à-dire choisir :\n",
    "+ Un **optimiseur** : comment on réalise la descente de gradient, \n",
    "+ Une **fonction de perte** que l'on cherche à minimiser,\n",
    "+ Une **métrique d'évaluation** du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7656db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler à l'aide de compile avec un optimiseur \"sgd\" (descente de gradient stochastique), une perte de crossentropy \n",
    "#(attention, on fait de la classification)\n",
    "# la métrique sera l'accuracy\n",
    "\n",
    "model.compile(optimizer='...', loss='...', metrics=['...'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55414ea1",
   "metadata": {},
   "source": [
    "# Entrainement du modèle (version simple, on verra plus compliqué plus tard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abca62",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On va entraîner le modèle avec *.fit* et préciser un certain nombre d'hyperparamètres :\n",
    "\n",
    "+ les données x_train et y_train,\n",
    "+ la taille des batchs : en général une puissance de 2, moins on a de puissance, plus on doit réduire la taille,\n",
    "+ le nombre d'epochs, i.e le nombre de fois où l'on applique la descente de gradient sur l'ensemble du réseau, \n",
    "+ le pourcentage de données d'entrainement qui servent à valider.\n",
    "\n",
    "Il y en a plein d'autres ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4844e81",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041e914",
   "metadata": {},
   "source": [
    "# Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceda902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# réaliser l'évaluation du modèle sur les données de test avec \".evaluate\"\n",
    "\n",
    "\n",
    "loss, accuracy = model. ......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755284d",
   "metadata": {},
   "source": [
    "# Sortie graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a70233",
   "metadata": {},
   "source": [
    "Il est courant de représenter graphiquement la perte et la métrique d'évaluation pour comprendre comment se passe l'entrainement. \n",
    "\n",
    "Il peut y avoir des décrochages de l'accuracy sur les données d'entraînement, ce qui traduit d'un surapprentissage ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f5d67",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axhline(accuracy, color='red')\n",
    "plt.legend(['Training', 'Validation', 'Test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Sur les données de test, le modèle obtient une perte de {loss} et une accuracy de {accuracy}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039b1b5",
   "metadata": {},
   "source": [
    "# Retour sur l'architecture et les poids d'un réseau FC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2b634",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour bien comprendre l'architecture d'un réseau, on peut aussi regarder les poids et biais.\n",
    "\n",
    "Remettons-nous en mémoire sur un exemple simple comment ça marche :\n",
    "    \n",
    "![image](simple_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3cb12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('===== Coefficients du réseau ====='.center(50))\n",
    "print('=== Couche d\\'entrée ===')\n",
    "print(f'Les deux premières lignes de la matrice de poids \\\n",
    "de la couche d\\'entrée est de la forme : \\n {model.weights[0][:2]}')\n",
    "print(f\"C'est une matrice de taille : {model.weights[0].shape}\")\n",
    "print('  =====================  ')\n",
    "print(f'Le vecteur de biais est de la forme : \\n{model.weights[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa7c9b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('===== Coefficients du réseau ====='.center(50))\n",
    "print('=== Couche d\\'entrée ===')\n",
    "print(f'Les deux premières lignes de la matrice de poids \\\n",
    "             de la couche d\\'entrée est de la forme : \\n {model.weights[2][:2]}')\n",
    "print(f\"C'est une matrice de taille : {model.weights[2].shape}\")\n",
    "print('  =====================  ')\n",
    "print(f'Le vecteur de biais est de la forme : \\n{model.weights[3]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a3b57",
   "metadata": {},
   "source": [
    "# Vers des modèles plus compliqués \n",
    "\n",
    "Cette partie est optionnelle, mais fait partie des bonnes pratiques. \n",
    "Les futurs option IA le reverront."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53009699",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #FCF550; border-radius: 10px; border: 5px solid  orange; padding: 5px;height: auto; margin: auto;\">\n",
    "    On va introduire un autre modèle et voir comment le nombre de paramètres évolue. \n",
    "\n",
    "De plus on va utiliser l'API Fonctionelle de Keras, i.e manipuler les tenseur et les couches comme des fonctions de tenseurs qui renvoient des tenseurs. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple :\n",
    "\n",
    "input_tensor = Input(shape=(784,))\n",
    "x = layers.Dense(1000, activation='tanh')(input_tensor)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# On définit alors le modèle avec la class Model\n",
    "\n",
    "model_functional = Model(input_tensor, output_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a91560",
   "metadata": {},
   "source": [
    "Cette façon de coder le modèle est notamment très utile quand il y a plusieurs entrées et/ou sorties au modèle.\n",
    "\n",
    "Regardons le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49363ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_functional.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab9848",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FCF550; border-radius: 10px; border: 5px solid  red; padding: 5px;height: auto; margin: auto;\">\n",
    "    <strong>Le nombre de paramètres explose !</strong>\n",
    "\n",
    "Faisons l'entraînement avec d'autres hyperparamètres. Cela permettra de voir au passage si l'on obtient de meilleures performances avec 28 fois plus de paramètres ! </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_functional.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391ac3c",
   "metadata": {},
   "source": [
    "On va aussi en profiter pour introduire des callbacks.\n",
    "Ne vous inquiètez pas, c'est des techniques plus ou moins avancées pour vous montrer ce que Keras permet de faire.   \n",
    "**Vous ne serez pas évaluer là dessus.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f437653",
   "metadata": {},
   "source": [
    "+ Le **EarlyStopping** interrompt l'entraînement si les performences du modèle n'augmente plus sur la métrique *monitor* (ici acc) au bout de *patience* (ici 10) epochs,\n",
    "\n",
    "+ **ReduceLROnPlateau** surveille la perte du modèle sur l'ensemble de validation en multipliant le taux d'apprentissage (learning rate, lr) par *factor*=0.1 au bout de *patience*=5 époques s'il n'y pas d'améliorations pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbackslist=[keras.callbacks.EarlyStopping(monitor='accuracy', patience=10),\n",
    "               keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b172f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_functional.fit(x_train, y_train, epochs=30, batch_size=16, callbacks=callbackslist, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy  = model_functional.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee17eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axhline(accuracy, color='red')\n",
    "plt.legend(['Training', 'Validation', 'Test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Sur les données de test, le modèle obtient une perte de {loss} et une accuracy de {accuracy}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc1106",
   "metadata": {},
   "source": [
    "Comparer avec le modèle simple. Quelle analyse pouvez-vous faire ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
